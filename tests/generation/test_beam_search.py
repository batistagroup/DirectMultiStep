"""
Tests for beam search functionality in DirectMultiStep.
"""

import pickle
from pathlib import Path

import numpy as np
import pytest
import torch

from directmultistep.generate import create_beam_search, prepare_input_tensors
from directmultistep.utils.dataset import RoutesProcessing

torch.manual_seed(42)
np.random.seed(42)


@pytest.mark.ckptreq
class TestBeamSearch:
    """Test suite for beam search functionality."""

    @pytest.fixture(scope="class")
    def test_data(self):
        """Load test data generated by save-data-for-tests.py."""
        test_data_path = Path("tests/test_data/beam_search_simple_test_data.pkl")
        if not test_data_path.exists():
            pytest.skip("Test data not found. Run scripts/save-data-for-tests.py to generate.")

        with open(test_data_path, "rb") as f:
            return pickle.load(f)

    @pytest.fixture(scope="class")
    def comprehensive_test_data(self):
        """Load comprehensive test data with intermediate results."""
        test_data_path = Path("tests/test_data/beam_search_comprehensive_test_data.pkl")
        if not test_data_path.exists():
            pytest.skip("Comprehensive test data not found. Run scripts/save-data-for-tests.py to generate.")

        with open(test_data_path, "rb") as f:
            return pickle.load(f)

    @pytest.fixture(scope="class")
    def model_components(self):
        """Load model and beam search components."""
        config_path = Path("data/configs/dms_dictionary.yaml")
        ckpt_dir = Path("data/checkpoints")

        if not config_path.exists() or not ckpt_dir.exists():
            pytest.skip("Model files not found. Ensure data is downloaded.")

        from directmultistep.generate import create_beam_search, load_published_model

        model = load_published_model("flash", ckpt_dir)
        rds = RoutesProcessing(metadata_path=config_path)
        beam_obj = create_beam_search(model, beam_size=5, rds=rds)

        return model, rds, beam_obj

    def test_beam_search_initialization(self, model_components):
        """Test that beam search object can be initialized properly."""
        model, rds, beam_obj = model_components

        assert beam_obj.model == model
        assert beam_obj.beam_size == 5
        assert beam_obj.start_idx == 0
        assert beam_obj.pad_idx == 52
        assert beam_obj.end_idx == 22
        assert beam_obj.max_length == 1074
        assert isinstance(beam_obj.idx_to_token, dict)
        assert isinstance(beam_obj.device, torch.device)

    def test_beam_search_decode_shape(self, model_components, test_data):
        """Test that beam search decode returns correct output shape."""
        model, rds, beam_obj = model_components

        # Use first test case
        case_name = "target1"
        if case_name not in test_data or test_data[case_name] is None:
            pytest.skip(f"Test data for {case_name} not available")

        case_info = test_data[case_name]["case_info"]

        # Prepare input tensors
        encoder_inp, steps_tens, path_tens = prepare_input_tensors(
            case_info["target"],
            case_info["n_steps"],
            case_info["starting_material"],
            rds,
            rds.product_max_length,
            rds.sm_max_length,
        )

        # Run beam search
        results = beam_obj.decode(
            src_BC=encoder_inp.to(beam_obj.device),
            steps_B1=steps_tens.to(beam_obj.device) if steps_tens is not None else None,
            path_start_BL=path_tens.to(beam_obj.device),
            progress_bar=False,
        )

        # Check output shape and structure
        assert isinstance(results, list)
        assert len(results) == 1  # Single batch
        assert isinstance(results[0], list)
        assert len(results[0]) == 5  # beam_size

        # Check each beam result
        for beam_result in results[0]:
            assert isinstance(beam_result, tuple)
            assert len(beam_result) == 2
            assert isinstance(beam_result[0], str)  # Path string
            assert isinstance(beam_result[1], float)  # Log probability

    def test_beam_search_reproducibility(self, model_components, comprehensive_test_data):
        """Test that beam search produces reproducible results with same seed."""
        model, rds, beam_obj = model_components

        case_name = "target1"
        if case_name not in comprehensive_test_data or comprehensive_test_data[case_name] is None:
            pytest.skip(f"Comprehensive test data for {case_name} not available")

        case_data = comprehensive_test_data[case_name]
        intermediate_data = case_data["intermediate_data"]

        # Set seed for reproducibility
        torch.manual_seed(42)

        # Run beam search with same inputs
        results = beam_obj.decode(
            src_BC=intermediate_data["encoder_input"].to(beam_obj.device),
            steps_B1=intermediate_data["steps_tensor"].to(beam_obj.device)
            if intermediate_data["steps_tensor"] is not None
            else None,
            path_start_BL=intermediate_data["path_start_tensor"].to(beam_obj.device),
            progress_bar=False,
        )

        # The beam search returns all beam results
        assert len(results[0]) == beam_obj.beam_size  # Should return full beam results

        # Verify the top result is valid
        if results[0]:
            actual_top_seq, actual_top_logprob = results[0][0]
            assert isinstance(actual_top_seq, str)
            assert len(actual_top_seq) > 0  # Should produce some output
            assert isinstance(actual_top_logprob, float)

    def test_beam_search_with_different_beam_sizes(self, model_components):
        """Test beam search with different beam sizes."""
        model, rds, _ = model_components

        # Test case
        target = "CNCc1cc(-c2ccccc2F)n(S(=O)(=O)c2cccnc2)c1"
        starting_material = "CN"
        n_steps = 2

        # Prepare input tensors
        encoder_inp, steps_tens, path_tens = prepare_input_tensors(
            target, n_steps, starting_material, rds, rds.product_max_length, rds.sm_max_length
        )

        device = next(model.parameters()).device
        encoder_inp = encoder_inp.to(device)
        steps_tens = steps_tens.to(device) if steps_tens is not None else None
        path_tens = path_tens.to(device)

        # Test different beam sizes
        for beam_size in [1, 3, 5]:
            beam_obj = create_beam_search(model, beam_size, rds)
            results = beam_obj.decode(
                src_BC=encoder_inp, steps_B1=steps_tens, path_start_BL=path_tens, progress_bar=False
            )

            assert len(results[0]) == beam_size

            # Check that all results are valid
            for path, log_prob in results[0]:
                assert isinstance(path, str)
                assert isinstance(log_prob, float)
                assert not torch.isnan(torch.tensor(log_prob))

    def test_beam_search_empty_results(self, model_components):
        """Test beam search behavior with invalid inputs."""
        model, rds, beam_obj = model_components

        # Test with characters that are not in the vocabulary
        invalid_target = "XYZ123invalid"

        # This should fail gracefully with a KeyError for unknown characters
        with pytest.raises(KeyError):
            encoder_inp, steps_tens, path_tens = prepare_input_tensors(
                invalid_target, 1, None, rds, rds.product_max_length, rds.sm_max_length
            )

    def test_beam_search_edge_cases(self, model_components):
        """Test beam search with edge case inputs."""
        model, rds, beam_obj = model_components

        # Test with valid but simple molecule
        simple_target = "C"  # Methane

        encoder_inp, steps_tens, path_tens = prepare_input_tensors(
            simple_target, 1, None, rds, rds.product_max_length, rds.sm_max_length
        )

        results = beam_obj.decode(
            src_BC=encoder_inp.to(beam_obj.device),
            steps_B1=steps_tens.to(beam_obj.device) if steps_tens is not None else None,
            path_start_BL=path_tens.to(beam_obj.device),
            progress_bar=False,
        )

        # Should return valid results
        assert isinstance(results, list)
        assert len(results) == 1
        assert len(results[0]) == beam_obj.beam_size

    def test_beam_search_step_by_step(self, comprehensive_test_data):
        """Test individual beam search steps using saved intermediate data."""
        case_name = "target1"
        if case_name not in comprehensive_test_data or comprehensive_test_data[case_name] is None:
            pytest.skip(f"Comprehensive test data for {case_name} not available")

        case_data = comprehensive_test_data[case_name]
        step_data = case_data["beam_search_steps"]

        # Verify that we have step data
        assert len(step_data) > 0

        # Check first step
        first_step = step_data[0]
        assert "decoder_output" in first_step
        assert "log_probs" in first_step
        assert "beam_indices" in first_step
        assert "step" in first_step

        # Verify tensor shapes are reasonable
        decoder_output = first_step["decoder_output"]
        log_probs = first_step["log_probs"]

        assert decoder_output.dim() == 2  # Should be (beam_size, vocab_size)
        assert log_probs.dim() == 2  # Should be (beam_size, vocab_size)
        assert decoder_output.shape == log_probs.shape

        # Check that log probabilities are valid
        assert not torch.isnan(log_probs).any()
        assert (log_probs <= 0).all()  # Log probabilities should be <= 0

    def test_exact_sequence_reproduction(self, model_components, comprehensive_test_data):
        """Test exact reproduction of generated sequences with fixed seed."""
        model, rds, beam_obj = model_components

        case_name = "target1"
        if case_name not in comprehensive_test_data or comprehensive_test_data[case_name] is None:
            pytest.skip(f"Comprehensive test data for {case_name} not available")

        case_data = comprehensive_test_data[case_name]
        intermediate_data = case_data["intermediate_data"]

        # Check if raw_beam_results exists (new format)
        if "raw_beam_results" not in case_data:
            pytest.skip("Test data needs to be regenerated with raw_beam_results")

        expected_beam_results = case_data["raw_beam_results"]

        # Set seed for reproducibility
        torch.manual_seed(42)
        np.random.seed(42)

        # Call the actual decode method
        results = beam_obj.decode(
            src_BC=intermediate_data["encoder_input"].to(beam_obj.device),
            steps_B1=intermediate_data["steps_tensor"].to(beam_obj.device)
            if intermediate_data["steps_tensor"] is not None
            else None,
            path_start_BL=intermediate_data["path_start_tensor"].to(beam_obj.device),
            progress_bar=False,
        )

        # Extract sequences and log probs from results
        actual_sequences = [path for path, _ in results[0]]
        actual_log_probs = [log_prob for _, log_prob in results[0]]

        # Extract expected sequences and log probs
        expected_sequences = [path for path, _ in expected_beam_results[0]]
        expected_log_probs = [log_prob for _, log_prob in expected_beam_results[0]]

        # Test exact sequence reproduction
        assert len(actual_sequences) == len(expected_sequences), (
            f"Should generate {len(expected_sequences)} sequences, got {len(actual_sequences)}"
        )

        for i, (actual, expected) in enumerate(zip(actual_sequences, expected_sequences, strict=False)):
            assert actual == expected, f"Beam {i}: Sequence mismatch.\nExpected: {expected}\nActual: {actual}"

        # Test exact log probability reproduction
        for i, (actual_lp, expected_lp) in enumerate(zip(actual_log_probs, expected_log_probs, strict=False)):
            assert abs(actual_lp - expected_lp) < 1e-5, (
                f"Beam {i}: Log prob mismatch. Expected: {expected_lp:.6f}, Actual: {actual_lp:.6f}"
            )

    def test_exact_sequence_reproduction_target2(self, model_components, comprehensive_test_data):
        """Test exact reproduction for second target molecule."""
        model, rds, beam_obj = model_components

        case_name = "target2"
        if case_name not in comprehensive_test_data or comprehensive_test_data[case_name] is None:
            pytest.skip(f"Comprehensive test data for {case_name} not available")

        case_data = comprehensive_test_data[case_name]
        intermediate_data = case_data["intermediate_data"]

        # Check if raw_beam_results exists (new format)
        if "raw_beam_results" not in case_data:
            pytest.skip("Test data needs to be regenerated with raw_beam_results")

        expected_beam_results = case_data["raw_beam_results"]

        # Set seed for reproducibility
        torch.manual_seed(42)
        np.random.seed(42)

        # Call the actual decode method
        results = beam_obj.decode(
            src_BC=intermediate_data["encoder_input"].to(beam_obj.device),
            steps_B1=intermediate_data["steps_tensor"].to(beam_obj.device)
            if intermediate_data["steps_tensor"] is not None
            else None,
            path_start_BL=intermediate_data["path_start_tensor"].to(beam_obj.device),
            progress_bar=False,
        )

        # Extract sequences and log probs
        actual_sequences = [path for path, _ in results[0]]
        actual_log_probs = [log_prob for _, log_prob in results[0]]
        expected_sequences = [path for path, _ in expected_beam_results[0]]
        expected_log_probs = [log_prob for _, log_prob in expected_beam_results[0]]

        # Test exact sequence reproduction
        assert len(actual_sequences) == len(expected_sequences)

        for i, (actual, expected) in enumerate(zip(actual_sequences, expected_sequences, strict=False)):
            assert actual == expected, f"Target2 Beam {i}: Sequence mismatch.\nExpected: {expected}\nActual: {actual}"

        # Test exact log probability reproduction
        for i, (actual_lp, expected_lp) in enumerate(zip(actual_log_probs, expected_log_probs, strict=False)):
            assert abs(actual_lp - expected_lp) < 1e-5, (
                f"Target2 Beam {i}: Log prob mismatch. Expected: {expected_lp:.6f}, Actual: {actual_lp:.6f}"
            )

    def test_top_beam_values(self, model_components, comprehensive_test_data):
        """Test specific values for the top-ranked beam."""
        model, rds, beam_obj = model_components

        case_name = "target1"
        if case_name not in comprehensive_test_data or comprehensive_test_data[case_name] is None:
            pytest.skip(f"Comprehensive test data for {case_name} not available")

        case_data = comprehensive_test_data[case_name]
        intermediate_data = case_data["intermediate_data"]

        # Check if raw_beam_results exists (new format)
        if "raw_beam_results" not in case_data:
            pytest.skip("Test data needs to be regenerated with raw_beam_results")

        expected_beam_results = case_data["raw_beam_results"]

        # Set seed for reproducibility
        torch.manual_seed(42)
        np.random.seed(42)

        # Call decode
        results = beam_obj.decode(
            src_BC=intermediate_data["encoder_input"].to(beam_obj.device),
            steps_B1=intermediate_data["steps_tensor"].to(beam_obj.device)
            if intermediate_data["steps_tensor"] is not None
            else None,
            path_start_BL=intermediate_data["path_start_tensor"].to(beam_obj.device),
            progress_bar=False,
        )

        # Get top beam (highest scoring)
        top_sequence, top_log_prob = results[0][0]
        expected_top_sequence, expected_top_log_prob = expected_beam_results[0][0]

        # Assert exact match for top beam
        assert top_sequence == expected_top_sequence, (
            f"Top sequence mismatch.\nExpected: {expected_top_sequence}\nActual: {top_sequence}"
        )

        assert abs(top_log_prob - expected_top_log_prob) < 1e-6, (
            f"Top log prob mismatch. Expected: {expected_top_log_prob:.8f}, Actual: {top_log_prob:.8f}"
        )

        # Verify log prob is a reasonable value (negative, not too extreme)
        assert top_log_prob < 0, "Log probability should be negative"
        assert top_log_prob > -1000, "Log probability should not be extremely negative"

        # Verify sequence is non-empty and contains expected characters
        assert len(top_sequence) > 0, "Generated sequence should not be empty"

    def test_beam_ordering(self, model_components, comprehensive_test_data):
        """Test that beams are ordered by log probability (highest first)."""
        model, rds, beam_obj = model_components

        case_name = "target1"
        if case_name not in comprehensive_test_data or comprehensive_test_data[case_name] is None:
            pytest.skip(f"Comprehensive test data for {case_name} not available")

        case_data = comprehensive_test_data[case_name]
        intermediate_data = case_data["intermediate_data"]

        # Set seed for reproducibility
        torch.manual_seed(42)
        np.random.seed(42)

        # Call decode
        results = beam_obj.decode(
            src_BC=intermediate_data["encoder_input"].to(beam_obj.device),
            steps_B1=intermediate_data["steps_tensor"].to(beam_obj.device)
            if intermediate_data["steps_tensor"] is not None
            else None,
            path_start_BL=intermediate_data["path_start_tensor"].to(beam_obj.device),
            progress_bar=False,
        )

        # Extract log probs
        log_probs = [log_prob for _, log_prob in results[0]]

        # Verify beams are sorted by log probability (highest to lowest)
        for i in range(len(log_probs) - 1):
            assert log_probs[i] >= log_probs[i + 1], (
                f"Beams should be ordered by log probability: beam {i} ({log_probs[i]:.6f}) should be >= beam {i + 1} ({log_probs[i + 1]:.6f})"
            )
